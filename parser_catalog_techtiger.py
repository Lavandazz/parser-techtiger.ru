import time
import os
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import json



headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36",
    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
}

session = requests.Session()
session.cookies.update({'cookie_name': 'cookie_value'})
response = requests.get('https://techtiger.ru/catalog/', headers=headers)
url_for_json = 'https://techtiger.ru'
SAVE_DIR = 'data_json'
# JSON_FILE = "save_products.json"
options = webdriver.ChromeOptions()
# options.add_argument("--headless")  # –±–µ–∑–≥–æ–ª–æ–≤—ã–π —Ä–µ–∂–∏–º
driver = webdriver.Chrome(options=options)

def get_link():
    """ –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–∏—Ö, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ json """
    list_of_products = {}

    soup = BeautifulSoup(response.text, 'html.parser')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º BeautifulSoup –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.
    products = soup.find_all('div', class_='item_block lg col-lg-20 col-md-4 col-xs-6')
    for link in products:
        category_url = link.find('a').get('href')
        category_name = link.text.strip('\n').split()[0].replace('/', '_')
        list_of_products[category_name] = url_for_json + category_url

    return list_of_products


def reed_json_list():
    """ –ß–∏—Ç–∞–µ–º —Ç–æ–≤–∞—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏–∑ json """
    with open('list_of_products.json', "r", encoding="utf-8") as file:
        dict_from_json = json.load(file)
        for name_category, link_text in dict_from_json.items():
            print(f"–í–∑—è–ª —Å—Å—ã–ª–∫—É - {link_text}")
            scrol_to_end(name_category, link_text)
            time.sleep(10)


def scrol_to_end(name_category: str, link_category: str):
    """ –°–∫—Ä–æ–ª–ª–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø–æ–º–æ—â—å—é Selenium """
    scrl_count = 0
    driver.get(link_category)
    # driver.get('https://techtiger.ru/catalog/podveska/')
    last_height = driver.execute_script("return document.body.scrollHeight")
    while True:
        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)  # —Å–∫—Ä–æ–ª–ª –¥–æ –∫–æ–Ω—Ü–∞
        time.sleep(5)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            print("‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
            break
        last_height = new_height
        scrl_count += 1
        print(f'—Å–∫—Ä–æ–ª–ª–∏–º –¥–∞–ª—å—à–µ')

        save_products(driver, name_category)

    print(f'–í—Å–µ–≥–æ —Å–∫—Ä–æ–ª–ª–æ–≤ = {scrl_count}')


def save_products(driver, name_category: str):
    """ –°–æ–±–∏—Ä–∞–µ—Ç —Ç–æ–≤–∞—Ä—ã –∏ –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Ö –≤ JSON-—Ñ–∞–π–ª """
    # JSON_FILE = "save_products.json"
    JSON_FILE = os.path.join(SAVE_DIR, f"{name_category}_save_products.json")
    page_source = driver.page_source  # –ø–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ—Å–ª–µ –ø—Ä–æ–∫—Ä—É—Ç–∫–∏
    soup = BeautifulSoup(page_source, 'html.parser')
    products = soup.find_all('div', class_='item_info')
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
    try:
        with open(JSON_FILE, "r", encoding="utf-8") as file:
            find_list_json = json.load(file)
            print('–æ—Ç–∫—Ä—ã–ª —Ñ–∞–π–ª')
    except (FileNotFoundError, json.JSONDecodeError):
        find_list_json = []  # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å
        print("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π.")

    print(f"üìÇ –¢–µ–∫—É—â–∏–µ —Ç–æ–≤–∞—Ä—ã –≤ JSON –ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π: {len(find_list_json)}")
    for product in products:
        product_url = url_for_json + product.find('a').get('href')

        product_name_tag = product.find('div', class_='item-title')
        product_name = product_name_tag.text.strip() if product_name_tag else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"

        price_tag = product.find('div', class_='price font-bold font_mxs')
        price = price_tag['data-value'] if price_tag and 'data-value' in price_tag.attrs else "–ù–µ—Ç —Ü–µ–Ω—ã"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–æ–≤–∞—Ä –≤ —Å–ø–∏—Å–∫–µ (–ø–æ –∏–º–µ–Ω–∏)
        if not any(item["name"] == product_name for item in find_list_json):
            find_list_json.append({"name": product_name, "price": price, "url": product_url})
            # print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {product_name} - {price} —Ä—É–±.")

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª
    with open(JSON_FILE, "w", encoding="utf-8") as file:
        json.dump(find_list_json, file, indent=4, ensure_ascii=False)

    print(f"–¢–æ–≤–∞—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {JSON_FILE}")

# get_link()

# list_of_products = get_link()
# with open('list_of_products.json', "w", encoding="utf-8") as file:
#     json.dump(list_of_products, file, indent=4, ensure_ascii=False)
# print("‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ categories.json")

reed_json_list()
driver.quit()




